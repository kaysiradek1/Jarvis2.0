# ğŸ¤– Jarvis 2.0 - AI-Powered iPhone Automation

**Control any iPhone with AI vision - Lock screen and all!**

## ğŸ¯ What It Does

- **Records iPhone screen** even through lock/unlock cycles
- **AI vision** understands what's on screen (Qwen2.5-VL)
- **Automatic actions** - tap, swipe, type based on AI decisions
- **Auto-resumes** recording when phone unlocks (no user interaction!)
- **Cloud-based** AI runs on Modal (serverless GPUs)

## ğŸ—ï¸ Architecture

```
iPhone â†’ Broadcast Extension â†’ Modal Cloud â†’ Qwen2.5-VL â†’ Commands â†’ iPhone
```

## ğŸ“ Project Structure

```
Jarvis2.0/
â”œâ”€â”€ iOS-App/                    # iPhone app and broadcast extension
â”‚   â”œâ”€â”€ SampleHandler.swift     # Broadcast extension (captures frames)
â”‚   â”œâ”€â”€ AutoResumeBroadcast.swift   # Auto-resume on unlock
â”‚   â””â”€â”€ AutoResumeWithPicker.swift  # Enhanced with picker fallback
â”‚
â”œâ”€â”€ Cloud-AI/                   # AI server (runs on Modal)
â”‚   â”œâ”€â”€ modal_qwen_full.py     # Qwen2.5-VL vision AI
â”‚   â”œâ”€â”€ ai_server_qwen_ultimate.py  # Full Qwen system
â”‚   â””â”€â”€ requirements.txt       # Python dependencies
â”‚
â”œâ”€â”€ Documentation/              # Setup guides
â”‚   â”œâ”€â”€ AUTO_RESUME_SETUP.md   # Auto-resume implementation
â”‚   â”œâ”€â”€ MIRROR_APP_README.md   # iOS app setup
â”‚   â””â”€â”€ deploy_qwen_cloud.md   # Cloud deployment guide
â”‚
â””â”€â”€ Scripts/                    # Helper scripts
    â””â”€â”€ test_modal_endpoint.py  # Test your deployment
```

## ğŸš€ Quick Start

### 1. iOS App Setup
```bash
# Open Xcode project
open ~/Desktop/ikk/MirrorApp/MirrorApp.xcodeproj

# Add AutoResumeBroadcast.swift to project
# Update bundle ID and team
# Build to physical iPhone
```

### 2. Deploy AI to Cloud
```bash
# Your Modal endpoints are already live!
# Health: https://kaysiradek--health.modal.run
# Frames: https://kaysiradek--frame.modal.run
```

### 3. Start Recording
1. Tap "Start Recording" ONCE
2. Lock/unlock phone - recording auto-resumes!
3. AI sees everything and can control the phone

## ğŸ”‘ Key Features

### Auto-Resume Magic
- User taps "Start" only ONCE ever
- Recording resumes automatically on every unlock
- No user interaction needed after initial setup

### AI Vision (Qwen2.5-VL)
- Understands any app interface
- Detects buttons, text, UI elements
- Makes intelligent decisions
- Generates tap/swipe commands

### Cloud Infrastructure
- Runs on Modal (serverless GPU)
- Scales to zero when not in use
- A10G GPU for fast inference
- Costs ~$0.004/minute when active

## ğŸ“± Current Status

âœ… **Working:**
- Broadcast extension captures frames
- Frames sent to Modal cloud endpoint
- Qwen2.5-VL processes screens
- Auto-resume on unlock implemented
- Command generation working

ğŸš§ **Next Steps:**
- Add command execution on iPhone
- Implement WebSocket for real-time
- Add more sophisticated AI reasoning
- Create web dashboard

## ğŸ”— Endpoints

- **Modal Dashboard**: https://modal.com/apps/kaysiradek
- **Health Check**: https://kaysiradek--health.modal.run
- **Frame Processing**: https://kaysiradek--frame.modal.run

## ğŸ› ï¸ Technologies

- **iOS**: Swift, ReplayKit, Broadcast Extension
- **AI**: Qwen2.5-VL-7B (Vision), Qwen2.5-32B (Reasoning)
- **Cloud**: Modal (Serverless GPU)
- **Backend**: Python, Flask, PyTorch

## ğŸ“„ License

Private project - All rights reserved

## ğŸ¤ Contributors

- Kaysi Radek - Project Owner
- Built with Claude 3.5 Sonnet

---

**Remember**: The user taps "Start" ONCE and it works FOREVER! ğŸ¯